{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d9fc8f-66f3-4478-a32e-3f968c8ef90f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Can Dilia be a youth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d44661-1ebe-46fa-ae20-88f6ff96a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bf34f1-0309-4910-a65f-97bb5868b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and some constants\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import uproot as ur\n",
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9613808f-7b2a-4a3f-ba19-d5ecc3f2981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my worspace and directories\n",
    "\n",
    "path_prefix = '/home/dportill/LCStudies/'\n",
    "plotpath = path_prefix+'classifier/Plots/'\n",
    "modelpath = path_prefix+'classifier/Models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5d1181-edd0-445a-bb25-aa71a8dfffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our resolution utilities\n",
    "\n",
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "from  util import resolution_util as ru\n",
    "from  util import plot_util as pu\n",
    "from  util import ml_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397b371f-c683-4cc1-be29-a25f7e282fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data v7 with images from pubnote\n",
    "\n",
    "inputpath = '/fast_scratch/atlas_images/v7/'\n",
    "rootfiles = [\"pi0\", \"piplus\", \"piminus\"]\n",
    "\n",
    "#setupPionData(inputpath, rootfiles, branches = []) on ml_util with defaultBranches from ClusterTree\n",
    "trees, pdata = mu.setupPionData(inputpath, rootfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8e68f8-ce3f-4118-9905-af3b8415af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pi0 events: 263891\n",
      "Number of pi+ events: 435967\n",
      "Number of pi- events: 434627\n",
      "Total: 1134485\n"
     ]
    }
   ],
   "source": [
    "# pdata -> Dictionary of dataframes. \"pi0\", \"piplus\", \"piminus\" are separated inside of the dictionary\n",
    "\n",
    "np0 = len(pdata['pi0'])\n",
    "npp = len(pdata['piplus'])\n",
    "npm = len(pdata['piminus'])\n",
    "\n",
    "print(\"Number of pi0 events: {}\".format(np0))\n",
    "print(\"Number of pi+ events: {}\".format(npp))\n",
    "print(\"Number of pi- events: {}\".format(npm))\n",
    "print(\"Total: {}\".format(np0+npp+npm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33197bfc-3c50-45ce-9feb-97002a260d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells = {\n",
    "    ifile : {\n",
    "        layer : mu.setupCells(itree, layer, flatten = False)\n",
    "        for layer in mu.cell_meta\n",
    "    }\n",
    "    for ifile, itree in trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3811d87c-afdc-44d7-8e04-f5e24c269251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# * PRINTING *\n",
    "# pcells is a dictionary of dictionaries of arrays with keys 'pi0','piplus'and 'piminus' \n",
    "#that has the layers as keys: EMB1, EMB2, EMB3, TileBar0, TileBar1, TileBar2 defined on cell_meta\n",
    "#with dimension of the arrays as len_phi x len_eta\n",
    "\n",
    "#print(pcells['pi0']['TileBar0']) #neutral pions some no zero values on first TileBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7d4ad7-8989-426f-9174-96b6b490a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846840f8-ed82-4d99-8cf1-abce72538792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b080889-e688-455b-ae02-4eeb2cad2df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For taking multiple gpus:\n",
    "#gpu_list = [\"/gpu:0\",\"/gpu:1\"]\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=gpu_list)\n",
    "#ngpu = strategy.num_replicas_in_sync\n",
    "#print ('Number of devices: {}'.format(ngpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62efa74-b713-4353-a6a5-7b1ffa3513ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just take one gpu:\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cec3d55-2fef-40ea-b916-4d9f50180655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/validation/test subsets containing 70%/10%/20%\n",
    "# of events from each type of pion event\n",
    "# merge pi0 and pi+ events\n",
    "training_classes = ['pi0','piplus']\n",
    "pdata_merged, pcells_merged, plabels = mu.createTrainingDatasets(training_classes, pdata, pcells)\n",
    "\n",
    "\n",
    "#pcells_merged -> huge nympy array with all pi0 first and then all pi+ data\n",
    "#A numpy arraw like this will remove all entries that are not true: pdata_merged.train\n",
    "#plabels -> which ones are pions plus or pi zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b34ca22-0a83-4d66-b465-b2da1afe6fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ********************************** p_index:  0 , plabel:  pi0\n",
      " ********************************** p_index:  1 , plabel:  piplus\n",
      "0         True\n",
      "1         True\n",
      "2         True\n",
      "3         True\n",
      "4         True\n",
      "          ... \n",
      "435962    True\n",
      "435963    True\n",
      "435964    True\n",
      "435965    True\n",
      "435966    True\n",
      "Name: label, Length: 435967, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# * PRINTING *\n",
    "\n",
    "for p_index, plabel in enumerate(training_classes):\n",
    "    print(\" ********************************** p_index: \", p_index, \", plabel: \", plabel)\n",
    "\n",
    "#pdata after createTrainingDatasets get a 'label' 0 if pi0 \n",
    "#print(pdata['pi0']['label']==0)\n",
    "print(pdata['piplus']['label']==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4895b591-874d-4a81-af17-baee37121f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcellsE23_EMB2G_channels = mu.setupChannelImages(mu.rescaleImages(pcells_merged, (16, 16), layers=['EMB2', 'EMB3']),last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "495e8be4-365b-4a38-936d-dbbb5d1f971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcellsE1_EMB1G_channels = mu.setupChannelImages(mu.rescaleImages(pcells_merged, (128, 4), layers=['EMB1']),last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ee4d4c5-df58-4339-906f-fe541affeb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcellsT123_T1G_channels = mu.setupChannelImages(mu.rescaleImages(pcells_merged, (4, 4), layers=['TileBar0', 'TileBar1', 'TileBar2']),last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e1175c-216e-4fab-9a5f-4175701bbd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_model(droprate=.5):\n",
    "    # EMB1 image (convolutional)\n",
    "    input1 = Input(shape=(128,4,1), name='emb1_input')\n",
    "    x1 = Convolution2D(32, (3, 3), padding='same', name='emb1_conv2d_1')(input1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    # x1 = Dropout(droprate)(x1)\n",
    "    x1 = Convolution2D(32, (3, 3), padding='same', name='emb1_conv2d_2')(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPool2D(pool_size=(2, 1), padding='same', name='emb1_maxpool_3')(x1)\n",
    "    x1 = Convolution2D(64, (3, 3), padding='same', name='emb1_conv2d_3')(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    #x1 = Dropout(droprate)(x1)\n",
    "    x1 = Convolution2D(64, (3, 3), padding='same', name='emb1_conv2d_4')(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPool2D(pool_size=(2, 1), padding='same', name='emb1_maxpool_5')(x1)\n",
    "    x1 = Convolution2D(128, (2, 2), padding='same', name='emb1_conv2d_6')(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Convolution2D(128, (2, 2), padding='same', name='emb1_conv2d_7')(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPool2D(pool_size=(2, 1), padding='same', name='emb1_maxpool_8')(x1)\n",
    "    x1 = Dropout(droprate, name='emb1_dropout_4')(x1)\n",
    "    x1 = Flatten(name='emb1_flatten_9')(x1)\n",
    "    x1 = Dense(128, activation='relu', name='emb1_dense_9')(x1)\n",
    "\n",
    "    # EMB23 image (convolutional)\n",
    "    input2 = Input(shape=(16,16,2), name='emb23_input')\n",
    "    x2 = Convolution2D(32, (1, 1), padding='same', name='emb23_conv1d_1')(input2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    # x2 = Dropout(droprate)(x2)\n",
    "    x2 = Convolution2D(64, (2, 2), padding='same', name='emb23_conv2d_2')(x2)\n",
    "    # x2 = Dropout(droprate)(x2)\n",
    "    x2 = MaxPool2D(pool_size=(2, 2), padding='same', name='emb23_maxpool_3')(x2)\n",
    "    x2 = Convolution2D(128, (2, 2), padding='same', name='emb23_conv2d_4')(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    # x2 = Dropout(droprate)(x2)\n",
    "    x2 = Convolution2D(128, (2, 2), padding='same', name='emb23_conv2d_5')(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPool2D(pool_size=(2, 2), padding='same', name='emb23_maxpool_6')(x2)\n",
    "    x2 = Dropout(droprate, name='emb23_dropout_4')(x2)\n",
    "    x2 = Flatten(name='emb23_flatten_7')(x2)\n",
    "    x2 = Dense(128, activation='relu', name='emb23_dense_8')(x2)\n",
    "\n",
    "    # tiles image (convolutional)\n",
    "    input3 = Input(shape=(4,4,3), name='tiles_input')\n",
    "    x3 = Convolution2D(32, (1, 1), padding='same', name='tiles_conv1d_1')(input3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "    # x3 = Dropout(droprate)(x3)\n",
    "    x3 = Convolution2D(64, (2, 2), padding='same', name='tiles_conv2d_2')(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "    # x3 = Dropout(droprate)(x3)\n",
    "    x3 = Convolution2D(128, (2, 2), padding='same', name='tiles_conv2d_3')(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "    x3 = MaxPool2D(pool_size=(2, 2), padding='same', name='tiles_maxpool_4')(x3)\n",
    "    x3 = Dropout(droprate, name='tiles_dropout_4')(x3)\n",
    "    x3 = Flatten(name='tiles_flatten_5')(x3)\n",
    "    x3 = Dense(128, activation='relu', name='tiles_dense_6')(x3)\n",
    "\n",
    "    # concatenate outputs from the two networks above\n",
    "    x = concatenate([x1, x2, x3], name='concatenate') \n",
    "    x = Dropout(droprate, name='concate_dropout_5')(x)\n",
    "    x = Dense(64, name='concated_dense_1')(x)    \n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(droprate, name='dense_dropout_6')(x)\n",
    "\n",
    "    # final output\n",
    "    output = Dense(2, activation='softmax', name='dense_output')(x)\n",
    "    # output = 5*tf.math.tanh(x)   # 0 to +5 range\n",
    "\n",
    "    model = Model(inputs = [input1, input2, input3], outputs = [output])\n",
    "    \n",
    "    # compile model\n",
    "    # model = multi_gpu_model(model, gpus=4)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56ba0819-647c-400b-bd95-1e2afabab94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p1_d02 = merged_model(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e213166-4bb4-4693-ace8-76926200f3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#history_p1_d02 = model_p1_d02.fit([pcellsE1_EMB1G_channels[pdata_merged.train], \n",
    "#                                pcellsE23_EMB2G_channels[pdata_merged.train], \n",
    "#                                pcellsT123_T1G_channels[pdata_merged.train]],\n",
    "#                                plabels[pdata_merged.train],\n",
    "#                                validation_data=([pcellsE1_EMB1G_channels[pdata_merged.val], \n",
    "#                                                    pcellsE23_EMB2G_channels[pdata_merged.val], \n",
    "#                                                    pcellsT123_T1G_channels[pdata_merged.val]], \n",
    "#                                                    plabels[pdata_merged.val]),\n",
    "#                                epochs=50,\n",
    "#                                batch_size = 128,     #*ngpu,\n",
    "#                                verbose=2\n",
    "#                                # use_multiprocessing=False\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebf4c04f-0487-4111-852b-86194efacc23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": " No execution plan worked!\n\t [[node model/tiles_conv1d_1/Conv2D (defined at <ipython-input-21-e8326b59a8c0>:2) ]] [Op:__inference_train_function_2188]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e8326b59a8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### Testing less epochs than 250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history_p1_d02 = model_p1_d02.fit([pcellsE1_EMB1G_channels[pdata_merged.train], \n\u001b[0m\u001b[1;32m      3\u001b[0m                                 \u001b[0mpcellsE23_EMB2G_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpdata_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 pcellsT123_T1G_channels[pdata_merged.train]],\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mplabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpdata_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m:  No execution plan worked!\n\t [[node model/tiles_conv1d_1/Conv2D (defined at <ipython-input-21-e8326b59a8c0>:2) ]] [Op:__inference_train_function_2188]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "##### Testing less epochs than 250\n",
    "history_p1_d02 = model_p1_d02.fit([pcellsE1_EMB1G_channels[pdata_merged.train], \n",
    "                                pcellsE23_EMB2G_channels[pdata_merged.train], \n",
    "                                pcellsT123_T1G_channels[pdata_merged.train]],\n",
    "                                plabels[pdata_merged.train],\n",
    "                                validation_data=([pcellsE1_EMB1G_channels[pdata_merged.val], \n",
    "                                                    pcellsE23_EMB2G_channels[pdata_merged.val], \n",
    "                                                    pcellsT123_T1G_channels[pdata_merged.val]], \n",
    "                                                    plabels[pdata_merged.val]),\n",
    "                                epochs=2,\n",
    "                                batch_size = 128,\n",
    "                                verbose=2\n",
    "                                # use_multiprocessing=False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed978f-efae-4331-acc1-82ee52c86c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9179715-475c-4d8f-af94-87a5106716a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
